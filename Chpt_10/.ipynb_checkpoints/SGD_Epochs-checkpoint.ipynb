{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067aabc7-d05b-4b2b-887a-6c272396e324",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea608e-9ec3-4f86-8cc8-3d36c070d318",
   "metadata": {},
   "source": [
    "## With Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1750aa52-1bd7-404c-9638-bbbc1a0454ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0985943\n",
      "acc: 0.36\n"
     ]
    }
   ],
   "source": [
    "%run SGD.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55d1901-194e-4c81-b5e9-de96d54b09c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.400, loss: 1.099\n",
      "epoch: 100, acc: 0.397, loss: 1.087\n",
      "epoch: 200, acc: 0.417, loss: 1.077\n",
      "epoch: 300, acc: 0.420, loss: 1.076\n",
      "epoch: 400, acc: 0.403, loss: 1.074\n",
      "epoch: 500, acc: 0.400, loss: 1.071\n",
      "epoch: 600, acc: 0.420, loss: 1.067\n",
      "epoch: 700, acc: 0.440, loss: 1.062\n",
      "epoch: 800, acc: 0.427, loss: 1.055\n",
      "epoch: 900, acc: 0.387, loss: 1.064\n",
      "epoch: 1000, acc: 0.403, loss: 1.062\n",
      "epoch: 1100, acc: 0.437, loss: 1.063\n",
      "epoch: 1200, acc: 0.403, loss: 1.061\n",
      "epoch: 1300, acc: 0.387, loss: 1.054\n",
      "epoch: 1400, acc: 0.400, loss: 1.055\n",
      "epoch: 1500, acc: 0.393, loss: 1.070\n",
      "epoch: 1600, acc: 0.403, loss: 1.055\n",
      "epoch: 1700, acc: 0.430, loss: 1.045\n",
      "epoch: 1800, acc: 0.403, loss: 1.031\n",
      "epoch: 1900, acc: 0.437, loss: 1.028\n",
      "epoch: 2000, acc: 0.433, loss: 1.048\n",
      "epoch: 2100, acc: 0.480, loss: 1.010\n",
      "epoch: 2200, acc: 0.413, loss: 1.019\n",
      "epoch: 2300, acc: 0.517, loss: 1.027\n",
      "epoch: 2400, acc: 0.460, loss: 0.997\n",
      "epoch: 2500, acc: 0.513, loss: 0.992\n",
      "epoch: 2600, acc: 0.490, loss: 1.000\n",
      "epoch: 2700, acc: 0.467, loss: 0.978\n",
      "epoch: 2800, acc: 0.490, loss: 0.977\n",
      "epoch: 2900, acc: 0.460, loss: 0.986\n",
      "epoch: 3000, acc: 0.517, loss: 0.975\n",
      "epoch: 3100, acc: 0.533, loss: 0.982\n",
      "epoch: 3200, acc: 0.537, loss: 0.992\n",
      "epoch: 3300, acc: 0.487, loss: 0.974\n",
      "epoch: 3400, acc: 0.487, loss: 0.972\n",
      "epoch: 3500, acc: 0.537, loss: 0.972\n",
      "epoch: 3600, acc: 0.523, loss: 0.996\n",
      "epoch: 3700, acc: 0.540, loss: 0.956\n",
      "epoch: 3800, acc: 0.587, loss: 0.994\n",
      "epoch: 3900, acc: 0.493, loss: 0.961\n",
      "epoch: 4000, acc: 0.497, loss: 0.973\n",
      "epoch: 4100, acc: 0.513, loss: 0.966\n",
      "epoch: 4200, acc: 0.537, loss: 0.985\n",
      "epoch: 4300, acc: 0.547, loss: 0.954\n",
      "epoch: 4400, acc: 0.577, loss: 0.985\n",
      "epoch: 4500, acc: 0.497, loss: 0.957\n",
      "epoch: 4600, acc: 0.503, loss: 0.967\n",
      "epoch: 4700, acc: 0.527, loss: 0.973\n",
      "epoch: 4800, acc: 0.543, loss: 0.986\n",
      "epoch: 4900, acc: 0.557, loss: 0.965\n",
      "epoch: 5000, acc: 0.567, loss: 0.988\n",
      "epoch: 5100, acc: 0.503, loss: 0.972\n",
      "epoch: 5200, acc: 0.523, loss: 0.968\n",
      "epoch: 5300, acc: 0.547, loss: 0.995\n",
      "epoch: 5400, acc: 0.547, loss: 0.953\n",
      "epoch: 5500, acc: 0.563, loss: 1.000\n",
      "epoch: 5600, acc: 0.527, loss: 0.958\n",
      "epoch: 5700, acc: 0.520, loss: 0.948\n",
      "epoch: 5800, acc: 0.527, loss: 0.971\n",
      "epoch: 5900, acc: 0.570, loss: 0.934\n",
      "epoch: 6000, acc: 0.580, loss: 0.958\n",
      "epoch: 6100, acc: 0.557, loss: 0.940\n",
      "epoch: 6200, acc: 0.550, loss: 0.946\n",
      "epoch: 6300, acc: 0.537, loss: 0.928\n",
      "epoch: 6400, acc: 0.600, loss: 0.942\n",
      "epoch: 6500, acc: 0.550, loss: 0.923\n",
      "epoch: 6600, acc: 0.610, loss: 0.943\n",
      "epoch: 6700, acc: 0.587, loss: 0.893\n",
      "epoch: 6800, acc: 0.577, loss: 0.893\n",
      "epoch: 6900, acc: 0.580, loss: 0.857\n",
      "epoch: 7000, acc: 0.610, loss: 0.914\n",
      "epoch: 7100, acc: 0.613, loss: 0.857\n",
      "epoch: 7200, acc: 0.600, loss: 0.878\n",
      "epoch: 7300, acc: 0.560, loss: 0.889\n",
      "epoch: 7400, acc: 0.613, loss: 0.856\n",
      "epoch: 7500, acc: 0.587, loss: 0.877\n",
      "epoch: 7600, acc: 0.673, loss: 0.862\n",
      "epoch: 7700, acc: 0.620, loss: 0.854\n",
      "epoch: 7800, acc: 0.623, loss: 0.884\n",
      "epoch: 7900, acc: 0.590, loss: 0.875\n",
      "epoch: 8000, acc: 0.603, loss: 0.877\n",
      "epoch: 8100, acc: 0.623, loss: 0.851\n",
      "epoch: 8200, acc: 0.603, loss: 0.843\n",
      "epoch: 8300, acc: 0.600, loss: 0.904\n",
      "epoch: 8400, acc: 0.640, loss: 0.890\n",
      "epoch: 8500, acc: 0.653, loss: 0.840\n",
      "epoch: 8600, acc: 0.613, loss: 0.848\n",
      "epoch: 8700, acc: 0.630, loss: 0.857\n",
      "epoch: 8800, acc: 0.620, loss: 0.854\n",
      "epoch: 8900, acc: 0.633, loss: 0.863\n",
      "epoch: 9000, acc: 0.627, loss: 0.880\n",
      "epoch: 9100, acc: 0.587, loss: 0.906\n",
      "epoch: 9200, acc: 0.593, loss: 0.868\n",
      "epoch: 9300, acc: 0.587, loss: 0.874\n",
      "epoch: 9400, acc: 0.610, loss: 0.878\n",
      "epoch: 9500, acc: 0.620, loss: 0.901\n",
      "epoch: 9600, acc: 0.613, loss: 0.864\n",
      "epoch: 9700, acc: 0.630, loss: 0.850\n",
      "epoch: 9800, acc: 0.637, loss: 0.822\n",
      "epoch: 9900, acc: 0.623, loss: 0.844\n",
      "epoch: 10000, acc: 0.603, loss: 0.902\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\n",
    "\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.outputs)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = loss_activation.forward(dense2.outputs, y)\n",
    "\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f\"epoch: {epoch}, \" + f\"acc: {accuracy:.3f}, \" + f\"loss: {loss:.3f}\")\n",
    "    \n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "    \n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a3eb7-ad1d-44bb-a1cc-dfb8e887cf81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
