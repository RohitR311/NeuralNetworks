{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21dc9755-d07a-48a5-ad67-1c6f0ddf52a0",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56e061-1759-4123-97bf-593a3a9ddd76",
   "metadata": {},
   "source": [
    "## Using Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2191ddf0-c322-464c-ad55-b4acbde97c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnfs\n",
    "import numpy as np\n",
    "from nnfs.datasets import spiral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bce0bd-fd61-46e1-9ac8-203b4aa88d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53bce3d-4dd5-45ea-859a-dd2dd518df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module = os.path.abspath(os.path.join(\"..\"))\n",
    "if module not in sys.path:\n",
    "    sys.path.append(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1744015-4091-4aef-ad7b-ee57f203f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chpt_9.NN_Classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b8dcb02-749e-4379-a9a2-1cf9788ea14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run SGD_Updated.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f61aa0-3059-4090-938b-841f1d2e758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a49df0-89ec-4afe-b4b3-681933a92853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Layer_Dense(2, 64)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "787aeece-e44b-49f4-afbb-120e82040efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer_SGD(decay=9e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493739e0-d462-4a9b-8a86-ee65ce4cc213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.400, loss: 1.088, lr: 0.918189330639978\n",
      "epoch: 200, acc: 0.423, loss: 1.078, lr: 0.8481044864727334\n",
      "epoch: 300, acc: 0.423, loss: 1.076, lr: 0.7879599716334411\n",
      "epoch: 400, acc: 0.413, loss: 1.075, lr: 0.7357810315650063\n",
      "epoch: 500, acc: 0.400, loss: 1.074, lr: 0.6900835001035125\n",
      "epoch: 600, acc: 0.397, loss: 1.072, lr: 0.6497303618998116\n",
      "epoch: 700, acc: 0.403, loss: 1.070, lr: 0.6138358602909582\n",
      "epoch: 800, acc: 0.420, loss: 1.067, lr: 0.5816997266011285\n",
      "epoch: 900, acc: 0.427, loss: 1.065, lr: 0.552761041401802\n",
      "epoch: 1000, acc: 0.433, loss: 1.062, lr: 0.5265652151018904\n",
      "epoch: 1100, acc: 0.440, loss: 1.057, lr: 0.502739932632849\n",
      "epoch: 1200, acc: 0.447, loss: 1.053, lr: 0.480977345967005\n",
      "epoch: 1300, acc: 0.427, loss: 1.049, lr: 0.4610206998294223\n",
      "epoch: 1400, acc: 0.410, loss: 1.041, lr: 0.44265415430923816\n",
      "epoch: 1500, acc: 0.413, loss: 1.032, lr: 0.4256949470009791\n",
      "epoch: 1600, acc: 0.433, loss: 1.024, lr: 0.40998729039399784\n",
      "epoch: 1700, acc: 0.437, loss: 1.015, lr: 0.39539757225890637\n",
      "epoch: 1800, acc: 0.460, loss: 1.011, lr: 0.3818105456072697\n",
      "epoch: 1900, acc: 0.427, loss: 1.021, lr: 0.36912627809973786\n",
      "epoch: 2000, acc: 0.420, loss: 1.018, lr: 0.35725768997177665\n",
      "epoch: 2100, acc: 0.413, loss: 1.015, lr: 0.34612855214426635\n",
      "epoch: 2200, acc: 0.413, loss: 1.012, lr: 0.3356718472021752\n",
      "epoch: 2300, acc: 0.420, loss: 1.008, lr: 0.32582841875468377\n",
      "epoch: 2400, acc: 0.437, loss: 1.003, lr: 0.3165458516666139\n",
      "epoch: 2500, acc: 0.437, loss: 1.000, lr: 0.3077775383952479\n",
      "epoch: 2600, acc: 0.450, loss: 0.995, lr: 0.2994818963193675\n",
      "epoch: 2700, acc: 0.457, loss: 0.991, lr: 0.2916217083199673\n",
      "epoch: 2800, acc: 0.460, loss: 0.986, lr: 0.2841635645477537\n",
      "epoch: 2900, acc: 0.473, loss: 0.981, lr: 0.27707738771438867\n",
      "epoch: 3000, acc: 0.483, loss: 0.977, lr: 0.2703360276824092\n",
      "epoch: 3100, acc: 0.480, loss: 0.973, lr: 0.2639149138317806\n",
      "epoch: 3200, acc: 0.493, loss: 0.969, lr: 0.2577917558196489\n",
      "epoch: 3300, acc: 0.493, loss: 0.965, lr: 0.25194628505202693\n",
      "epoch: 3400, acc: 0.497, loss: 0.961, lr: 0.2463600305486438\n",
      "epoch: 3500, acc: 0.510, loss: 0.957, lr: 0.24101612397869418\n",
      "epoch: 3600, acc: 0.517, loss: 0.953, lr: 0.235899129532212\n",
      "epoch: 3700, acc: 0.523, loss: 0.949, lr: 0.2309948950128202\n",
      "epoch: 3800, acc: 0.530, loss: 0.945, lr: 0.2262904211264737\n",
      "epoch: 3900, acc: 0.527, loss: 0.943, lr: 0.22177374642389833\n",
      "epoch: 4000, acc: 0.480, loss: 0.971, lr: 0.21743384575242983\n",
      "epoch: 4100, acc: 0.507, loss: 0.960, lr: 0.21326054040220938\n",
      "epoch: 4200, acc: 0.500, loss: 0.949, lr: 0.20924441840513905\n",
      "epoch: 4300, acc: 0.493, loss: 0.947, lr: 0.20537676367295807\n",
      "epoch: 4400, acc: 0.513, loss: 0.955, lr: 0.2016494928515255\n",
      "epoch: 4500, acc: 0.517, loss: 0.955, lr: 0.1980550989285219\n",
      "epoch: 4600, acc: 0.537, loss: 0.938, lr: 0.1945866007666712\n",
      "epoch: 4700, acc: 0.527, loss: 0.927, lr: 0.19123749784857816\n",
      "epoch: 4800, acc: 0.510, loss: 0.934, lr: 0.18800172961591247\n",
      "epoch: 4900, acc: 0.563, loss: 0.931, lr: 0.18487363886783384\n",
      "epoch: 5000, acc: 0.540, loss: 0.915, lr: 0.18184793875361424\n",
      "epoch: 5100, acc: 0.507, loss: 0.926, lr: 0.1789196829543218\n",
      "epoch: 5200, acc: 0.553, loss: 0.921, lr: 0.17608423869979398\n",
      "epoch: 5300, acc: 0.547, loss: 0.918, lr: 0.17333726231127905\n",
      "epoch: 5400, acc: 0.580, loss: 0.905, lr: 0.1706746769981738\n",
      "epoch: 5500, acc: 0.523, loss: 0.912, lr: 0.1680926526701518\n",
      "epoch: 5600, acc: 0.550, loss: 0.907, lr: 0.16558758755443692\n",
      "epoch: 5700, acc: 0.570, loss: 0.901, lr: 0.16315609143267362\n",
      "epoch: 5800, acc: 0.593, loss: 0.890, lr: 0.16079497033332796\n",
      "epoch: 5900, acc: 0.557, loss: 0.896, lr: 0.15850121253427588\n",
      "epoch: 6000, acc: 0.593, loss: 0.890, lr: 0.15627197574658938\n",
      "epoch: 6100, acc: 0.593, loss: 0.884, lr: 0.1541045753648426\n",
      "epoch: 6200, acc: 0.600, loss: 0.884, lr: 0.1519964736818106\n",
      "epoch: 6300, acc: 0.553, loss: 0.871, lr: 0.1499452699764586\n",
      "epoch: 6400, acc: 0.573, loss: 0.885, lr: 0.14794869139382463\n",
      "epoch: 6500, acc: 0.607, loss: 0.873, lr: 0.14600458454395468\n",
      "epoch: 6600, acc: 0.630, loss: 0.866, lr: 0.14411090775460794\n",
      "epoch: 6700, acc: 0.650, loss: 0.861, lr: 0.14226572391913617\n",
      "epoch: 6800, acc: 0.650, loss: 0.858, lr: 0.14046719388686774\n",
      "epoch: 6900, acc: 0.570, loss: 0.856, lr: 0.13871357034858722\n",
      "epoch: 7000, acc: 0.587, loss: 0.850, lr: 0.13700319217437765\n",
      "epoch: 7100, acc: 0.610, loss: 0.851, lr: 0.13533447916525693\n",
      "epoch: 7200, acc: 0.613, loss: 0.843, lr: 0.13370592718375207\n",
      "epoch: 7300, acc: 0.590, loss: 0.841, lr: 0.1321161036318717\n",
      "epoch: 7400, acc: 0.597, loss: 0.834, lr: 0.1305636432479012\n",
      "epoch: 7500, acc: 0.593, loss: 0.830, lr: 0.1290472441961002\n",
      "epoch: 7600, acc: 0.647, loss: 0.833, lr: 0.12756566442576317\n",
      "epoch: 7700, acc: 0.630, loss: 0.831, lr: 0.12611771827824092\n",
      "epoch: 7800, acc: 0.653, loss: 0.819, lr: 0.12470227332244267\n",
      "epoch: 7900, acc: 0.590, loss: 0.827, lr: 0.12331824740106793\n",
      "epoch: 8000, acc: 0.600, loss: 0.821, lr: 0.12196460587137613\n",
      "epoch: 8100, acc: 0.597, loss: 0.816, lr: 0.12064035902570847\n",
      "epoch: 8200, acc: 0.600, loss: 0.813, lr: 0.11934455967824704\n",
      "epoch: 8300, acc: 0.613, loss: 0.808, lr: 0.11807630090564522\n",
      "epoch: 8400, acc: 0.613, loss: 0.805, lr: 0.11683471393020294\n",
      "epoch: 8500, acc: 0.617, loss: 0.802, lr: 0.11561896613520481\n",
      "epoch: 8600, acc: 0.617, loss: 0.798, lr: 0.11442825920289273\n",
      "epoch: 8700, acc: 0.627, loss: 0.795, lr: 0.11326182736632272\n",
      "epoch: 8800, acc: 0.623, loss: 0.793, lr: 0.1121189357670617\n",
      "epoch: 8900, acc: 0.627, loss: 0.790, lr: 0.110998878911323\n",
      "epoch: 9000, acc: 0.637, loss: 0.788, lr: 0.10990097921772483\n",
      "epoch: 9100, acc: 0.637, loss: 0.785, lr: 0.10882458565039013\n",
      "epoch: 9200, acc: 0.637, loss: 0.784, lr: 0.10776907243159359\n",
      "epoch: 9300, acc: 0.640, loss: 0.781, lr: 0.1067338378286068\n",
      "epoch: 9400, acc: 0.640, loss: 0.779, lr: 0.10571830300980009\n",
      "epoch: 9500, acc: 0.637, loss: 0.777, lr: 0.1047219109654313\n",
      "epoch: 9600, acc: 0.640, loss: 0.775, lr: 0.1037441254888942\n",
      "epoch: 9700, acc: 0.643, loss: 0.773, lr: 0.10278443021451111\n",
      "epoch: 9800, acc: 0.647, loss: 0.772, lr: 0.1018423277082421\n",
      "epoch: 9900, acc: 0.660, loss: 0.770, lr: 0.10091733860794623\n",
      "epoch: 10000, acc: 0.663, loss: 0.769, lr: 0.1000090008100729\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\n",
    "\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.outputs)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = loss_activation.forward(dense2.outputs, y)\n",
    "\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(\n",
    "            f\"epoch: {epoch}, \"\n",
    "            + f\"acc: {accuracy:.3f}, \"\n",
    "            + f\"loss: {loss:.3f}, \"\n",
    "            + f\"lr: {optimizer.current_learning_rate}\"\n",
    "        )\n",
    "\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
