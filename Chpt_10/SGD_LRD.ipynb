{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21dc9755-d07a-48a5-ad67-1c6f0ddf52a0",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56e061-1759-4123-97bf-593a3a9ddd76",
   "metadata": {},
   "source": [
    "## Using Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2191ddf0-c322-464c-ad55-b4acbde97c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnfs\n",
    "import numpy as np\n",
    "from nnfs.datasets import spiral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bce0bd-fd61-46e1-9ac8-203b4aa88d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53bce3d-4dd5-45ea-859a-dd2dd518df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module = os.path.abspath(os.path.join(\"..\"))\n",
    "if module not in sys.path:\n",
    "    sys.path.append(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1744015-4091-4aef-ad7b-ee57f203f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chpt_9.NN_Classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b8dcb02-749e-4379-a9a2-1cf9788ea14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run SGD_Updated.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f61aa0-3059-4090-938b-841f1d2e758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a49df0-89ec-4afe-b4b3-681933a92853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Layer_Dense(2, 64)\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(64, 3)\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "787aeece-e44b-49f4-afbb-120e82040efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer_SGD(decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493739e0-d462-4a9b-8a86-ee65ce4cc213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, lr: 1.0\n",
      "epoch: 100, acc: 0.400, loss: 1.088, lr: 0.9099181073703367\n",
      "epoch: 200, acc: 0.423, loss: 1.078, lr: 0.8340283569641367\n",
      "epoch: 300, acc: 0.423, loss: 1.076, lr: 0.7698229407236336\n",
      "epoch: 400, acc: 0.420, loss: 1.076, lr: 0.7147962830593281\n",
      "epoch: 500, acc: 0.403, loss: 1.074, lr: 0.66711140760507\n",
      "epoch: 600, acc: 0.403, loss: 1.072, lr: 0.6253908692933083\n",
      "epoch: 700, acc: 0.410, loss: 1.070, lr: 0.5885815185403178\n",
      "epoch: 800, acc: 0.410, loss: 1.068, lr: 0.5558643690939411\n",
      "epoch: 900, acc: 0.427, loss: 1.066, lr: 0.526592943654555\n",
      "epoch: 1000, acc: 0.440, loss: 1.063, lr: 0.5002501250625312\n",
      "epoch: 1100, acc: 0.440, loss: 1.059, lr: 0.4764173415912339\n",
      "epoch: 1200, acc: 0.447, loss: 1.056, lr: 0.45475216007276037\n",
      "epoch: 1300, acc: 0.440, loss: 1.052, lr: 0.43497172683775553\n",
      "epoch: 1400, acc: 0.427, loss: 1.048, lr: 0.4168403501458941\n",
      "epoch: 1500, acc: 0.417, loss: 1.040, lr: 0.4001600640256102\n",
      "epoch: 1600, acc: 0.423, loss: 1.033, lr: 0.3847633705271258\n",
      "epoch: 1700, acc: 0.450, loss: 1.025, lr: 0.3705075954057058\n",
      "epoch: 1800, acc: 0.470, loss: 1.017, lr: 0.35727045373347627\n",
      "epoch: 1900, acc: 0.460, loss: 1.008, lr: 0.3449465332873405\n",
      "epoch: 2000, acc: 0.463, loss: 1.000, lr: 0.33344448149383127\n",
      "epoch: 2100, acc: 0.490, loss: 1.005, lr: 0.32268473701193934\n",
      "epoch: 2200, acc: 0.467, loss: 1.014, lr: 0.31259768677711786\n",
      "epoch: 2300, acc: 0.483, loss: 1.014, lr: 0.3031221582297666\n",
      "epoch: 2400, acc: 0.490, loss: 1.012, lr: 0.29420417769932333\n",
      "epoch: 2500, acc: 0.493, loss: 1.009, lr: 0.2857959416976279\n",
      "epoch: 2600, acc: 0.497, loss: 1.005, lr: 0.2778549597110308\n",
      "epoch: 2700, acc: 0.487, loss: 1.004, lr: 0.2703433360367667\n",
      "epoch: 2800, acc: 0.483, loss: 0.999, lr: 0.26322716504343247\n",
      "epoch: 2900, acc: 0.493, loss: 0.995, lr: 0.25647601949217746\n",
      "epoch: 3000, acc: 0.490, loss: 0.991, lr: 0.25006251562890724\n",
      "epoch: 3100, acc: 0.490, loss: 0.987, lr: 0.2439619419370578\n",
      "epoch: 3200, acc: 0.493, loss: 0.983, lr: 0.23815194093831865\n",
      "epoch: 3300, acc: 0.497, loss: 0.978, lr: 0.23261223540358225\n",
      "epoch: 3400, acc: 0.493, loss: 0.974, lr: 0.22732439190725165\n",
      "epoch: 3500, acc: 0.507, loss: 0.970, lr: 0.22227161591464767\n",
      "epoch: 3600, acc: 0.530, loss: 0.966, lr: 0.21743857360295715\n",
      "epoch: 3700, acc: 0.523, loss: 0.960, lr: 0.21281123643328367\n",
      "epoch: 3800, acc: 0.527, loss: 0.956, lr: 0.20837674515524068\n",
      "epoch: 3900, acc: 0.533, loss: 0.950, lr: 0.20412329046744235\n",
      "epoch: 4000, acc: 0.533, loss: 0.946, lr: 0.2000400080016003\n",
      "epoch: 4100, acc: 0.547, loss: 0.943, lr: 0.19611688566385566\n",
      "epoch: 4200, acc: 0.550, loss: 0.937, lr: 0.19234468166955185\n",
      "epoch: 4300, acc: 0.553, loss: 0.933, lr: 0.18871485185884126\n",
      "epoch: 4400, acc: 0.557, loss: 0.929, lr: 0.18521948508983144\n",
      "epoch: 4500, acc: 0.560, loss: 0.924, lr: 0.18185124568103292\n",
      "epoch: 4600, acc: 0.567, loss: 0.919, lr: 0.1786033220217896\n",
      "epoch: 4700, acc: 0.567, loss: 0.915, lr: 0.1754693805930865\n",
      "epoch: 4800, acc: 0.577, loss: 0.911, lr: 0.17244352474564578\n",
      "epoch: 4900, acc: 0.573, loss: 0.906, lr: 0.16952025767079165\n",
      "epoch: 5000, acc: 0.577, loss: 0.900, lr: 0.16669444907484582\n",
      "epoch: 5100, acc: 0.583, loss: 0.897, lr: 0.16396130513198884\n",
      "epoch: 5200, acc: 0.587, loss: 0.892, lr: 0.16131634134537828\n",
      "epoch: 5300, acc: 0.590, loss: 0.889, lr: 0.15875535799333226\n",
      "epoch: 5400, acc: 0.593, loss: 0.886, lr: 0.1562744178777934\n",
      "epoch: 5500, acc: 0.597, loss: 0.881, lr: 0.15386982612709646\n",
      "epoch: 5600, acc: 0.617, loss: 0.876, lr: 0.15153811183512653\n",
      "epoch: 5700, acc: 0.617, loss: 0.872, lr: 0.14927601134497687\n",
      "epoch: 5800, acc: 0.623, loss: 0.868, lr: 0.14708045300779526\n",
      "epoch: 5900, acc: 0.623, loss: 0.864, lr: 0.14494854326714016\n",
      "epoch: 6000, acc: 0.633, loss: 0.860, lr: 0.1428775539362766\n",
      "epoch: 6100, acc: 0.630, loss: 0.856, lr: 0.1408649105507818\n",
      "epoch: 6200, acc: 0.640, loss: 0.852, lr: 0.13890818169190167\n",
      "epoch: 6300, acc: 0.647, loss: 0.849, lr: 0.13700506918755992\n",
      "epoch: 6400, acc: 0.653, loss: 0.845, lr: 0.13515339910798757\n",
      "epoch: 6500, acc: 0.657, loss: 0.843, lr: 0.13335111348179757\n",
      "epoch: 6600, acc: 0.640, loss: 0.839, lr: 0.13159626266614027\n",
      "epoch: 6700, acc: 0.617, loss: 0.832, lr: 0.12988699831146902\n",
      "epoch: 6800, acc: 0.657, loss: 0.829, lr: 0.12822156686754713\n",
      "epoch: 6900, acc: 0.667, loss: 0.832, lr: 0.126598303582732\n",
      "epoch: 7000, acc: 0.663, loss: 0.827, lr: 0.12501562695336915\n",
      "epoch: 7100, acc: 0.660, loss: 0.825, lr: 0.12347203358439313\n",
      "epoch: 7200, acc: 0.673, loss: 0.821, lr: 0.12196609342602757\n",
      "epoch: 7300, acc: 0.657, loss: 0.817, lr: 0.12049644535486204\n",
      "epoch: 7400, acc: 0.667, loss: 0.814, lr: 0.11906179307060363\n",
      "epoch: 7500, acc: 0.657, loss: 0.811, lr: 0.11766090128250381\n",
      "epoch: 7600, acc: 0.653, loss: 0.808, lr: 0.11629259216187929\n",
      "epoch: 7700, acc: 0.647, loss: 0.806, lr: 0.11495574203931487\n",
      "epoch: 7800, acc: 0.647, loss: 0.804, lr: 0.11364927832708263\n",
      "epoch: 7900, acc: 0.643, loss: 0.802, lr: 0.11237217664906168\n",
      "epoch: 8000, acc: 0.647, loss: 0.799, lr: 0.11112345816201799\n",
      "epoch: 8100, acc: 0.647, loss: 0.797, lr: 0.10990218705352237\n",
      "epoch: 8200, acc: 0.640, loss: 0.796, lr: 0.10870746820306555\n",
      "epoch: 8300, acc: 0.643, loss: 0.794, lr: 0.1075384449940854\n",
      "epoch: 8400, acc: 0.643, loss: 0.793, lr: 0.10639429726566654\n",
      "epoch: 8500, acc: 0.637, loss: 0.791, lr: 0.10527423939362038\n",
      "epoch: 8600, acc: 0.640, loss: 0.790, lr: 0.10417751849150952\n",
      "epoch: 8700, acc: 0.640, loss: 0.788, lr: 0.10310341272296113\n",
      "epoch: 8800, acc: 0.643, loss: 0.787, lr: 0.1020512297173181\n",
      "epoch: 8900, acc: 0.643, loss: 0.785, lr: 0.10102030508132134\n",
      "epoch: 9000, acc: 0.647, loss: 0.784, lr: 0.1000100010001\n",
      "epoch: 9100, acc: 0.647, loss: 0.782, lr: 0.09901970492127933\n",
      "epoch: 9200, acc: 0.647, loss: 0.781, lr: 0.09804882831650162\n",
      "epoch: 9300, acc: 0.643, loss: 0.780, lr: 0.09709680551509856\n",
      "epoch: 9400, acc: 0.650, loss: 0.778, lr: 0.09616309260505818\n",
      "epoch: 9500, acc: 0.653, loss: 0.777, lr: 0.09524716639679968\n",
      "epoch: 9600, acc: 0.657, loss: 0.776, lr: 0.09434852344560807\n",
      "epoch: 9700, acc: 0.657, loss: 0.774, lr: 0.09346667912889055\n",
      "epoch: 9800, acc: 0.663, loss: 0.773, lr: 0.09260116677470137\n",
      "epoch: 9900, acc: 0.663, loss: 0.772, lr: 0.09175153683824203\n",
      "epoch: 10000, acc: 0.667, loss: 0.771, lr: 0.09091735612328393\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\n",
    "\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.outputs)\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = loss_activation.forward(dense2.outputs, y)\n",
    "\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(\n",
    "            f\"epoch: {epoch}, \"\n",
    "            + f\"acc: {accuracy:.3f}, \"\n",
    "            + f\"loss: {loss:.3f}, \"\n",
    "            + f\"lr: {optimizer.current_learning_rate}\"\n",
    "        )\n",
    "\n",
    "    loss_activation.backward(loss_activation.output, y)\n",
    "    dense2.backward(loss_activation.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.post_update_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
